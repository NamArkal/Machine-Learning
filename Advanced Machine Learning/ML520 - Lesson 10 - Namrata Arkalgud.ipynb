{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFLOW - Deploying Machine Learning in Production\n",
    "\n",
    "In this assignment you will be writing a script that train models and use `mlflow` to submit runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./new_data.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./new_data.json\n",
    "{\"age\": {\"0\": 40, \"1\": 47},\n",
    " \"balance\": {\"0\": 580, \"1\": 3644},\n",
    " \"campaign\": {\"0\": 1, \"1\": 2},\n",
    " \"contact\": {\"0\": \"unknown\", \"1\": \"unknown\"},\n",
    " \"day\": {\"0\": 16, \"1\": 9},\n",
    " \"default\": {\"0\": \"no\", \"1\": \"no\"},\n",
    " \"duration\": {\"0\": 192, \"1\": 83},\n",
    " \"education\": {\"0\": \"secondary\", \"1\": \"secondary\"},\n",
    " \"housing\": {\"0\": \"yes\", \"1\": \"no\"},\n",
    " \"job\": {\"0\": \"blue-collar\", \"1\": \"services\"},\n",
    " \"loan\": {\"0\": \"no\", \"1\": \"no\"},\n",
    " \"marital\": {\"0\": \"married\", \"1\": \"single\"},\n",
    " \"month\": {\"0\": \"may\", \"1\": \"jun\"},\n",
    " \"pdays\": {\"0\": -1, \"1\": -1},\n",
    " \"poutcome\": {\"0\": \"unknown\", \"1\": \"unknown\"},\n",
    " \"previous\": {\"0\": 0, \"1\": 0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all necessary libraries\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "# Load Dataset\n",
    "bank = pd.read_csv('bank-full.csv', delimiter = ';')\n",
    "\n",
    "# Split data between train and validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(bank.drop(columns = \"y\"), bank[\"y\"], \n",
    "                                                    test_size = 0.10, random_state = 42)\n",
    "\n",
    "X_train = X_train.reset_index(drop = True)\n",
    "X_test = X_test.reset_index(drop = True)\n",
    "onehoter = OneHotEncoder(handle_unknown='ignore', sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bank.info()\n",
    "# bank.describe()\n",
    "# bank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1: Create pre-processing function to be later used as part of the pipeline (custom transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformations(df):\n",
    "    cat_cols = X_train.select_dtypes(['object']).columns\n",
    "    onehoter.fit(X_train[cat_cols])\n",
    "    onehot_cols = [f'{col}_{cat}' for i, col in enumerate(X_train[cat_cols].columns) for cat in onehoter.categories_[i]]\n",
    "    res = onehoter.transform(df[cat_cols])\n",
    "    df_onehot = pd.DataFrame(res, columns=onehot_cols)\n",
    "   \n",
    "    num_cols = X_train.select_dtypes(['integer', 'float']).columns\n",
    "    znormalizer = StandardScaler()\n",
    "    znormalizer.fit(X_train[num_cols])\n",
    "    df_norm = znormalizer.transform(df[num_cols])\n",
    "    df_norm = pd.DataFrame(df_norm, columns=num_cols)\n",
    "\n",
    "    df_featurized = df_onehot \n",
    "    df_featurized[num_cols] = df_norm \n",
    "\n",
    "    del df_onehot, df_norm\n",
    "    return df_featurized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: Creating a custom transformer from the previously defined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processing = FunctionTransformer(train_transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3: Creating the pipeline and defining each of two steps: (i) pre-processing, and; (ii) model (Logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    [\"data_pre_processing\", pre_processing],\n",
    "    [\"model\", LogisticRegression()]\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4: Call `fit` and `predict` on the pipeline to make sure that it all works. Remember to pass them the **un-processed** (original) data, since the data processing should be built into the pipeline now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline]  (step 1 of 2) Processing data_pre_processing, total=   0.1s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('data_pre_processing',\n",
       "                 FunctionTransformer(func=<function train_transformations at 0x7fee48b4baf0>)),\n",
       "                ['model', LogisticRegression(solver='liblinear')]],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set parameters for Logistic Regression estimator ('model') inside the pipeline\n",
    "pipeline.set_params(model__C=1.0,                 # C: default=1.0\n",
    "                    model__solver='liblinear',   # solver: {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
    "                    model__max_iter=100,         # max_iter: default=100\n",
    "                    model__fit_intercept=True,   # fit_intercept:{True, False}, default=True\n",
    "                    model__penalty='l2')         # penalty: {‘l1’, ‘l2’, ‘elasticnet’, ‘none’}, default=’l2’ \n",
    "                                                 # Warning: The choice of the algorithm depends on the penalty chosen. \n",
    "                                                 #          Not all algorithms support every type of penalty \n",
    "\n",
    "#Fit Training Data to Model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "#Prediction on Training and Test Data\n",
    "# y_train_pred = #To Do\n",
    "# y_test_pred = #To Do\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5: Evaluate your model by calculating the precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Main Parameters used in logistic regression are: C=1.0, solver=liblinear, max_iter=100, fit_intercept=True and penalty=l2\n",
      "\n",
      "Precision = 0.66% and recall = 0.35% on the training data.\n",
      "Precision = 0.63% and recall = 0.34% on the validation data.\n"
     ]
    }
   ],
   "source": [
    "#Create a function to evaluate the model performance using precision and recall\n",
    "def eval_metrics(actual, pred):\n",
    "    precision = precision_score(actual, pred, pos_label='yes')\n",
    "    recall = recall_score(actual, pred, pos_label='yes')\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "#Calculation of evaluation metrics - Precision and Recall for training and validation data\n",
    "y_pred_train = pd.Series(pipeline.predict(X_train))\n",
    "(precision_train, recall_train) = eval_metrics(y_train, y_pred_train)\n",
    "y_pred_test = pd.Series(pipeline.predict(X_test))\n",
    "(precision_test, recall_test) = eval_metrics(y_test, y_pred_test)\n",
    "\n",
    "# Print Model (Logistic Regression) parameters\n",
    "print()\n",
    "print('Main Parameters used in logistic regression are: C={}, solver={}, max_iter={}, fit_intercept={} and penalty={}'.format(pipeline['model'].get_params()['C'],\n",
    "                                                                                                                             pipeline['model'].get_params()['solver'],\n",
    "                                                                                                                             pipeline['model'].get_params()['max_iter'],\n",
    "                                                                                                                             pipeline['model'].get_params()['fit_intercept'],\n",
    "                                                                                                                             pipeline['model'].get_params()['penalty']))\n",
    "# Print Evaluation Metrics for the Model (Logistic Regression)\n",
    "print()\n",
    "print('Precision = {:.2f}% and recall = {:.2f}% on the training data.'.format(precision_train, recall_train))\n",
    "print('Precision = {:.2f}% and recall = {:.2f}% on the validation data.'.format(precision_test, recall_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6: Save your pipeline object using `joblib` as shown [here](https://sklearn.org/modules/model_persistence.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipeline.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store 'pipeline' as pickle file using joblib\n",
    "joblib.dump(pipeline, 'pipeline.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 7: Now write a **new script** for scoring: it loads the pipeline you saved in the last step, reads the data `../data/new_data.json` and converts it to a `pandas.DataFrame` object, and obtains predictions on it. The predictions should be stored as a `json` file `../data/new_preds.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call and load stored 'pipeline' \n",
    "pipeline = joblib.load('pipeline.pkl')\n",
    "\n",
    "#Read json file with new data and write into a pandas dataframe  \n",
    "with open('./new_data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "new_predictions = pd.DataFrame(data)\n",
    "\n",
    "#Use predict method of pipeline to score (make prediction) on new data \n",
    "new_predictions['prediction'] = pd.Series(pipeline.predict(new_predictions))\n",
    "\n",
    "#Write predictions of new data into a json file\n",
    "new_predictions.to_json('./new_preds.json', orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    None\n",
      "1    None\n",
      "Name: prediction, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>campaign</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>default</th>\n",
       "      <th>duration</th>\n",
       "      <th>education</th>\n",
       "      <th>housing</th>\n",
       "      <th>job</th>\n",
       "      <th>loan</th>\n",
       "      <th>marital</th>\n",
       "      <th>month</th>\n",
       "      <th>pdays</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>previous</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>580</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>16</td>\n",
       "      <td>no</td>\n",
       "      <td>192</td>\n",
       "      <td>secondary</td>\n",
       "      <td>yes</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>no</td>\n",
       "      <td>married</td>\n",
       "      <td>may</td>\n",
       "      <td>-1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>3644</td>\n",
       "      <td>2</td>\n",
       "      <td>unknown</td>\n",
       "      <td>9</td>\n",
       "      <td>no</td>\n",
       "      <td>83</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>services</td>\n",
       "      <td>no</td>\n",
       "      <td>single</td>\n",
       "      <td>jun</td>\n",
       "      <td>-1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  balance  campaign  contact  day default  duration  education housing  \\\n",
       "0   40      580         1  unknown   16      no       192  secondary     yes   \n",
       "1   47     3644         2  unknown    9      no        83  secondary      no   \n",
       "\n",
       "           job loan  marital month  pdays poutcome  previous prediction  \n",
       "0  blue-collar   no  married   may     -1  unknown         0       None  \n",
       "1     services   no   single   jun     -1  unknown         0       None  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read json file containing predictions made for the new data and load them into a dataframe\n",
    "with open('./new_preds.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "new_pred_dataframe= pd.DataFrame(data)\n",
    "\n",
    "#Print predictions for each observation contained in the new_data.json file and the dataframe with the data and prediction\n",
    "print(new_pred_dataframe['prediction'])\n",
    "new_pred_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 8: Create a new text cell in your Notebook: Complete a 50-100 word summary (or short description of your thinking in applying this week's learning to the solution) of your experience in this assignment. Include: What was your incoming experience with this model, if any? what steps you took, what obstacles you encountered. how you link this exercise to real-world, machine learning problem-solving. (What steps were missing? What else do you need to learn?) This summary allows your instructor to know how you are doing and allot points for your effort in thinking and planning, and making connections to real-world work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incoming experience: No incoming experience apart from previous assignments.\n",
    "\n",
    "Steps taken: This week's lesson was about productionizing pipelines. Got a feel for how pipelines and joblib works and is used.\n",
    "\n",
    "Obstacles: Figuring out some errors with inputs passed to libraries.\n",
    "\n",
    "Link to real world: Helped me understand the different functions in Scikit learn and joblib.\n",
    "\n",
    "Steps missing (with just this week's learning): MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
