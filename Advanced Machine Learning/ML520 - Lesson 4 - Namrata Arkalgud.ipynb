{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 5 - Assignment\n",
    "\n",
    "In this assignment, you will implement a Support Vector Machine Classifier  from scratch and compare the results to existing sklearn algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# make this notebook's output stable across runs\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1.1: Implement the cost function cost/objective function:\n",
    "<img src=\"https://miro.medium.com/max/688/1*JAS6rUTO7TDlrv4XZSMbsA.png\" alt=\"drawing\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why isn't b an input here? Is it an assumed value of 0?\n",
    "def compute_cost(W, X, Y,reg_strength=1000):\n",
    "    # TODO calculate cost function\n",
    "    margin = 1 - Y * (np.dot(X, W))\n",
    "#     print(\"margin:\", margin)\n",
    "#     print(type(margin))\n",
    "#     margin = max(0, margin)\n",
    "    margin[margin < 0] = 0 \n",
    "    loss = reg_strength * (np.sum(margin) / X.shape[0])\n",
    "    cost = 0.5 * np.dot(W, W) + loss\n",
    "    print(\"cost:\", cost)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# margin = [-7.92120974e-01, -1.50753080e-01, -4.15360566e+00, 4.00352650e+00, -1.59051391e+00, -7.35799213e+00, -7.00967938e+00, -6.68023754e+00, 3.57708205e+00, 1.01718300e+00, -4.48967397e-01, -4.85633761e+00]\n",
    "\n",
    "# margin = np.array(margin)\n",
    "# margin[margin < 0] = 0 \n",
    "# margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1.2: Write a method that calculate the cost gradient:\n",
    "<img src=\"https://miro.medium.com/max/866/1*ww3F21VMVGp2NKhm0VTesA.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost_gradient(W, X_batch, Y_batch, reg_strength=1000):\n",
    "#     print(type(Y_batch))\n",
    "    if type(Y_batch) == np.int64:\n",
    "        Y_batch = np.array([Y_batch])\n",
    "        X_batch = np.array([X_batch])\n",
    "#     print(type(Y_batch))\n",
    "\n",
    "    distance = 1 - (Y_batch * np.dot(X_batch, W))\n",
    "    dw = np.zeros(len(W))\n",
    "\n",
    "    for ind, d in enumerate(distance):\n",
    "        if max(0, d) == 0:\n",
    "            di = W\n",
    "        else:\n",
    "            di = W - (reg_strength * Y_batch[ind] * X_batch[ind])\n",
    "        dw += di\n",
    "\n",
    "    dw = dw/len(Y_batch)  # average\n",
    "#     print(\"dw:\", dw)\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_cost_gradient( np.array([0.01, 0.01, 0.01, 1]), X_train.to_numpy(), 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1.3: Write a method that performs stochastic Gradient descent as follows:\n",
    "- Caluclate the gradient of cost function i.e. ∇J(w)\n",
    "- Update the weights in the opposite direction to the gradient: w = w — ∝(∇J(w))\n",
    "- Repeat until conversion or until 5000 epochs are reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data here is x train as 2D numpy array\n",
    "# outputs is y train as 1D numpy array\n",
    "def sgd(data, outputs, learning_rate = 0.0001, max_epochs = 5000):\n",
    "    weights = np.zeros(data.shape[1])\n",
    "    nth = 0\n",
    "    prev_cost = float(\"inf\")\n",
    "    cost_threshold = 0.01  # in percent\n",
    "    # stochastic gradient descent\n",
    "    for epoch in range(1, max_epochs):\n",
    "        # shuffle to prevent repeating update cycles\n",
    "        X, Y = shuffle(data, outputs)\n",
    "        for ind, x in enumerate(X):#TO DO\n",
    "            ascent = calculate_cost_gradient(weights, x, Y[ind])\n",
    "            weights = weights - (learning_rate * ascent)\n",
    "            # convergence check on 2^nth epoch\n",
    "            if (epoch == 2 ** nth) or (epoch == max_epochs - 1):\n",
    "                cost = compute_cost(weights, data, outputs)\n",
    "                print(\"Epoch is:{} and Cost is: {}\".format(epoch, cost))\n",
    "                # stoppage criterion\n",
    "                if abs(prev_cost - cost) < cost_threshold * prev_cost:\n",
    "                    return weights\n",
    "                prev_cost = cost\n",
    "                nth += 1\n",
    "    \n",
    "    print(\"weights:\", weights)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_banknote_authentication.csv')\n",
    "\n",
    "Y = data.iloc[:, -1]  \n",
    "X = data.iloc[:, 1:4]\n",
    "X.insert(loc=len(X.columns), column='intercept', value=1)\n",
    "\n",
    "Y.replace(to_replace=0,value=-1, inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4: Train and evaluate an SVC using the banknote_authentication data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1371 entries, 0 to 1370\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   8.6661     1371 non-null   float64\n",
      " 1   -2.8073    1371 non-null   float64\n",
      " 2   -0.44699   1371 non-null   float64\n",
      " 3   intercept  1371 non-null   int64  \n",
      "dtypes: float64(3), int64(1)\n",
      "memory usage: 43.0 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>8.6661</th>\n",
       "      <th>-2.8073</th>\n",
       "      <th>-0.44699</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1371.000000</td>\n",
       "      <td>1371.000000</td>\n",
       "      <td>1371.000000</td>\n",
       "      <td>1371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.917434</td>\n",
       "      <td>1.400694</td>\n",
       "      <td>-1.192200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.868359</td>\n",
       "      <td>4.310105</td>\n",
       "      <td>2.101683</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-13.773100</td>\n",
       "      <td>-5.286100</td>\n",
       "      <td>-8.548200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.711300</td>\n",
       "      <td>-1.553350</td>\n",
       "      <td>-2.417000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.313400</td>\n",
       "      <td>0.616630</td>\n",
       "      <td>-0.586650</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.813100</td>\n",
       "      <td>3.181600</td>\n",
       "      <td>0.394810</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.951600</td>\n",
       "      <td>17.927400</td>\n",
       "      <td>2.449500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            8.6661      -2.8073     -0.44699  intercept\n",
       "count  1371.000000  1371.000000  1371.000000     1371.0\n",
       "mean      1.917434     1.400694    -1.192200        1.0\n",
       "std       5.868359     4.310105     2.101683        0.0\n",
       "min     -13.773100    -5.286100    -8.548200        1.0\n",
       "25%      -1.711300    -1.553350    -2.417000        1.0\n",
       "50%       2.313400     0.616630    -0.586650        1.0\n",
       "75%       6.813100     3.181600     0.394810        1.0\n",
       "max      12.951600    17.927400     2.449500        1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe() # scaling might help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training started...\n",
      "cost: 1353.5403433279191\n",
      "Epoch is:1 and Cost is: 1353.5403433279191\n",
      "cost: 1361.2123100074366\n",
      "Epoch is:2 and Cost is: 1361.2123100074366\n",
      "training finished.\n",
      "weights are: [-2.29487291 -0.85304504 -1.51191052  1.38837604]\n",
      "accuracy on test dataset: 0.7522768670309654\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "print(\"training started...\")\n",
    "W = sgd(X_train.to_numpy(), y_train.to_numpy())\n",
    "# W = sgd(X_train, y_train.to_numpy())\n",
    "print(\"training finished.\")\n",
    "print(\"weights are: {}\".format(W))\n",
    "\n",
    "# testing the model on test set\n",
    "y_test_predicted = np.array([])\n",
    "for i in range(X_test.shape[0]):\n",
    "    yp = np.sign(np.dot(W, X_test.to_numpy()[i]))\n",
    "#     yp = np.sign(np.dot(W, X_test[i]))\n",
    "    y_test_predicted = np.append(y_test_predicted, yp)\n",
    "print(\"accuracy on test dataset: {}\".format(accuracy_score(y_test.to_numpy(), y_test_predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Bonus] Question 5: Train and evaluate an SKLEARN SVC model, and compare the results to your model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9562841530054644"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(gamma='auto')\n",
    "svc.fit(X_train, y_train)\n",
    "pred = svc.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6: Create a new text cell in your Notebook: Complete a 50-100 word summary (or short description of your thinking in applying this week's learning to the solution) of your experience in this assignment. Include: What was your incoming experience with this model, if any? what steps you took, what obstacles you encountered. how you link this exercise to real-world, machine learning problem-solving. (What steps were missing? What else do you need to learn?) This summary allows your instructor to know how you are doing and allot points for your effort in thinking and planning, and making connections to real-world work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incoming experience: No incoming experience apart from previous assignments.\n",
    "\n",
    "Steps taken: This week's lesson was about SVM's. Implementing it helped get a better understanding of what lies under the hood w.r.t. implementation and what kind of data the functions work with.\n",
    "\n",
    "Obstacles: Got a few type errors and value errors, took a while to fix the errors.\n",
    "\n",
    "Link to real world: Helped me understand when SVM's can be used versus other algorithms and how SVM's can be scaled to non-linear and multi dimensional problems.\n",
    "\n",
    "Steps missing (with just this week's learning): I thought data needed to be scaled but accuracy reduced after scaling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
