{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Sequence-to-Sequence: Language Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "In this assignment you will use a database of pairs of English and French sentences to train an RNN model to translate from English to French.\n",
    "\n",
    "The English versions of the training sentences are in the file \"small_vocab_en.txt\" and their French translations are in \"small_vocab_fr.txt\". The $n$-th line of the English file corresponds to the $n$-th line of the French file. They are bundled with this starter notebook in the download on Canvas.  To get started, you should have used `scp` to copy the tar file to your Azure VM, and uncompressed it with:\n",
    "```\n",
    "tar zxf Seq-to-Seq-NL-Translation.tar.gz\n",
    "```\n",
    "to reveal the French and English training data and the starter notebook within, which you're presumably reading now.\n",
    "\n",
    "**As in previous assignments, watch out for `TODO` and `QUESTION` marks in the notebook for cells containing pieces of code you need to complete, or cells where you should write answers in Markdown format.**\n",
    "\n",
    "Some additional resources you might find helpful are listed below.\n",
    "\n",
    "Keras resources: \n",
    "* https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html A quick discussion of using sequence-to-sequence methods in translation that corresponds well to what you do in this assignment.\n",
    "* https://machinelearningmastery.com/return-sequences-and-return-states-for-lstms-in-keras/ Has a nice review of the potentially confusing `return_states` and `return_sequences` options that some of our recurrent layer units have in Keras.\n",
    "* https://stackoverflow.com/questions/38714959/understanding-keras-lstms/50235563#50235563\n",
    "\n",
    "Neural Language Translation Resources:\n",
    "* https://arxiv.org/abs/1703.01619 This is a 65 page tutorial on NLP in the \"just before Transformers\" era.  You might find it useful to consult, or a good thing to set aside for enrichment reading after the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't think we've used anything from scikit-learn yet in the course,\n",
    "so pop out to your terminal on the Azure VM, make sure your Conda \n",
    "environment with TensorFlow and friends installed is the currently active\n",
    "environment, and install scikit-learn with:\n",
    "```\n",
    "conda install -c conda-forge scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "# NOTE:\n",
    "# It's worth reading through this list of imports to see how many of them\n",
    "# feel familiar and comfortable at this stage of the course, and peeking at\n",
    "# the documentation for any that seem new or less familiar.\n",
    "#\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau # ReduceLROnPlateau is new to us--check out its docs!\n",
    "from keras.layers import Input, GRU, LSTM, Dense, Masking, Dropout, Embedding, Flatten, Dense\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import pad_sequences\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration Parameters for our Training Exercise\n",
    "\n",
    "A bunch of configuration parameters we'll use later on in the notebook.  Skim through them and make sure they all ring the correct bells in your mind when you see them.  Watch for them to appear later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TEST_SPLIT = 0.7           # % of data in training set\n",
    "\n",
    "NUM_LSTM_NODES = 256             # Num of intermediate LSTM nodes\n",
    "CONTEXT_VECTOR_SIZE = 256        # Size of context vector (num of LSTM nodes in final LSTM layer)\n",
    "\n",
    "EMBEDDING_DIM = 100              # Embedding layer size for input words\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "NUM_DATA_EXAMPLES = 5000         # limit memory usage\n",
    "\n",
    "LR = 0.01\n",
    "DROPOUT = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Massaging Text\n",
    "\n",
    "Remember that neural networks essentially just do almost linear algebra on multi-dimensional\n",
    "arrays of numbers, with various non-linearities sprinkled in amongst them so that our networks\n",
    "can learn to do more interesting things than pure matrix multiplication and vector addition could do.\n",
    "\n",
    "Thus, we always need to mess with text to get it into a format presentable to a neural net.\n",
    "What follows below is pretty close to the sort of stuff we discussed in class, but read through\n",
    "it and sanity check the details for yourself before moving on to put it into use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The symbols Python strings consider to be 'punctuation' by default\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_space_around_punctuation(s):\n",
    "    result = ''\n",
    "    for c in s:\n",
    "        if c in string.punctuation and c != \"'\":\n",
    "            result += ' %s ' % c\n",
    "        else:\n",
    "            result += c\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers for Cleaning the Text, Adding Stop/Stop Symbols, Etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(s):\n",
    "    s = s.strip()\n",
    "    s = s.lower()\n",
    "    s = add_space_around_punctuation(s)\n",
    "    return s\n",
    "\n",
    "def get_words_from_sentence(s, add_start_symbol=False, add_end_symbol=False, reverse=False):\n",
    "    words = list(filter(None, s.split(' ')))\n",
    "    if reverse:\n",
    "        words = words[::-1]\n",
    "    if add_start_symbol:\n",
    "        words = ['<S>'] + words\n",
    "    if add_end_symbol:\n",
    "        words.append('</S>')\n",
    "    return words\n",
    "\n",
    "def get_word_list_from_sentence_string(s, add_start_symbol=False, add_end_symbol=False, reverse=False):\n",
    "    return get_words_from_sentence(clean_sentence(s), add_start_symbol, add_end_symbol, reverse)    \n",
    "    \n",
    "def get_sentences(path, filename, add_start_symbol=False, add_end_symbol=False, reverse=False):\n",
    "    with open(os.path.join(path, filename), 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        return [get_word_list_from_sentence_string(s, add_start_symbol, add_end_symbol, reverse) \n",
    "                for s in lines]\n",
    "\n",
    "def get_word_set(sentences):\n",
    "    words = set()\n",
    "    for s in sentences:\n",
    "        for word in s:\n",
    "            words.add(word)\n",
    "    return words\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Training Data Plus a Neat Translator Training Trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data files\n",
    "PATH = '.'\n",
    "\n",
    "# Below is a trick you might remember us mentioning in class.  If you reverse the words in the\n",
    "# source text, the average distance between corresponding words in the source and target texts\n",
    "# remains unchanged, *but* the first few words in the source language are now very close to the\n",
    "# first few words in the target language.  In practice, LSTMs seem to learn better when we do\n",
    "# this reversal before training.  The phenomenon is not, AFAIK, very rigorously understood,\n",
    "# like many things in practical deep learning, but it may make the optimization problem easier\n",
    "# by helping \"establish communication\" between the source sentence and the target sentence.\n",
    "#\n",
    "# For more details, see: https://arxiv.org/abs/1409.3215 \n",
    "s1 = get_sentences(PATH, 'small_vocab_en.txt', reverse=True, add_end_symbol=False) # Reverse input sentences for training\n",
    "\n",
    "s2 = get_sentences(PATH, 'small_vocab_fr.txt', add_start_symbol=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only get a subset of the data\n",
    "s1 = s1[:NUM_DATA_EXAMPLES]\n",
    "s2 = s2[:NUM_DATA_EXAMPLES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = list(get_word_set(s1))\n",
    "w2 = list(get_word_set(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sometimes\n",
      "june\n",
      "it's\n",
      "quiet\n",
      "?\n",
      "china\n",
      "india\n",
      "pears\n",
      "march\n",
      "chilly\n",
      "\n",
      "déteste\n",
      "quand\n",
      "doux\n",
      "fraise\n",
      "?\n",
      "verte\n",
      "votre\n",
      "pomme\n",
      "détestez\n",
      "californie\n"
     ]
    }
   ],
   "source": [
    "for w in w1[:10]:\n",
    "    print(w)\n",
    "print()\n",
    "for w in w2[:10]:\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions for Going Between Words and Their Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_to_index_dict(words):\n",
    "    return {w: i+1 for i,w in enumerate(words)}  # use i+1 to reserve 0 for the mask index\n",
    "def reverse_dict(d):\n",
    "    return {v: k for k,v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index1 = get_word_to_index_dict(w1)\n",
    "word_to_index2 = get_word_to_index_dict(w2)\n",
    "index_to_word1 = reverse_dict(word_to_index1)\n",
    "index_to_word2 = reverse_dict(word_to_index2)\n",
    "index_to_word1[0] = '<MASK>'\n",
    "index_to_word2[0] = '<MASK>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_indices(s, word_to_index):\n",
    "    return [word_to_index[w] for w in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_sentence(indices, index_to_word):\n",
    "    return [index_to_word[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[277, 225, 66, 173, 184]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sentence_to_indices(get_word_list_from_sentence_string('vous aimez raisins.', add_start_symbol=True), word_to_index2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<S>', 'vous', 'aimez', 'raisins', '.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_to_sentence(x, index_to_word2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197, 309)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words_X = len(w1) + 1  # add 1 to reserve 0 for mask\n",
    "num_words_y = len(w2) + 1  # add 1 to reserve 0 for mask\n",
    "num_words_X, num_words_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_as_indices = [sentence_to_indices(s, word_to_index1) for s in s1]\n",
    "outputs_as_indices = [sentence_to_indices(s, word_to_index2) for s in s2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = pad_sequences(inputs_as_indices)\n",
    "outputs = pad_sequences(outputs_as_indices, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 23)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len_X = len(inputs[0])\n",
    "max_seq_len_y = len(outputs[0])\n",
    "max_seq_len_X, max_seq_len_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(inputs, outputs, \n",
    "                                                    test_size=1 - TRAIN_TEST_SPLIT,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to one-hot-encode the outputs ourselves for use in the loss function. \n",
    "# The inputs get this for free via use of Embedding layers in Keras.\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3499, 17), (1501, 17), (3499, 23), (1501, 23))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eyeball the shapes of the training and test sets...\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Now we need to write code to build the SeqToSeq model. \n",
    "\n",
    "**Important**: In Keras we have to use the \"functional API\" in order to access the LSTM internal state that we use as the \"context vector\" or \"encoding\" of a sentence. We also need to store hooks into the model to be able to run the translator on new sentences after training.\n",
    "\n",
    "This code will create variables representing the entire SeqToSeq model (for use in training), as well as the individual encoder segment and decoder segment of the model, for use in inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement the following architecture:\n",
    "    \n",
    "1. Encoder input: shape (max_seq_len_X,)\n",
    "2. Masking layer: doesn't change shape. Ignores leading \"-1\"s in shorter sequences.\n",
    "3. Embedding layer: output shape (max_seq_len_X, EMBEDDING_DIM)\n",
    "4. LSTM layer 1. N.B. The first LSTM layer in a stack must use \"return_sequences=True\"\n",
    "5. LSTM layer 2. N.B. The final layer must use \"return_state=True\" so we can extract the internal state (the context vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build RNN model.\n",
    "# See also: https://machinelearningmastery.com/define-encoder-decoder-sequence-sequence-model-neural-machine-translation-keras/\n",
    "\n",
    "encoding_size = CONTEXT_VECTOR_SIZE\n",
    "max_input_seq_len = max_seq_len_X\n",
    "max_output_seq_len = max_seq_len_y\n",
    "num_input_words = num_words_X\n",
    "num_output_words = num_words_y\n",
    "\n",
    "# TODO: Set up encoder Input layer\n",
    "encoder_inputs = Input(shape=(max_input_seq_len,), name='encoder_input')\n",
    "\n",
    "# TODO: Set up Masking layer--if you're forgetting what Masking is about, consult the Keras docs and/or the lecture\n",
    "encoder_inputs_masked = Masking(name='encoder_masking')(encoder_inputs)\n",
    "\n",
    "# TODO: Set up word Embedding layer we'll train\n",
    "encoder_inputs_embedded = Embedding(num_input_words, EMBEDDING_DIM, name='encoder_embedding')(encoder_inputs_masked)\n",
    "\n",
    "# Set up the first LSTM layer\n",
    "encoder_outputs0 = LSTM(NUM_LSTM_NODES, return_state=True, return_sequences=True, name='encoder_lstm_0')\n",
    "encoder_output0, state_h0, state_c0  =  encoder_outputs0(encoder_inputs_embedded)\n",
    "\n",
    "# Set up the second LSTM layer\n",
    "encoder_outputs1 = LSTM(NUM_LSTM_NODES, return_state=True, return_sequences=False, name='encoder_lstm_1')\n",
    "encoder_outputs1, state_h1, state_c1 = encoder_outputs1(encoder_output0)\n",
    "\n",
    "# Discard `encoder_outputs2` and only keep the states.\n",
    "encoder_states1 = [state_h1, state_c1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The decoder should have the following architecture:\n",
    "    \n",
    "1. Decoder input: shape (max_seq_len_y,)\n",
    "2. Masking layer: doesn't change shape. Ignores final \"-1\"s in shorter sequences.\n",
    "3. Embedding layer: output shape (max_seq_len_y, EMBEDDING_DIM)\n",
    "4. LSTM layer 1. N.B. The first LSTM layer in a stack must use \"return_sequences=True\", and the final layer must use \"return_state=True\" so we can extract the internal state; this decoder has only one LSTM layer so you'llmake both True.\n",
    "6. Dense layer with softmax: output shape (num_output_words,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder section\n",
    "# Set up the decoder, using encoder_states as initial state.\n",
    "\n",
    "# TODO: Set up Input layer as described above\n",
    "decoder_inputs = Input(shape=(max_output_seq_len,), name='decoder_input')\n",
    "# TODO: Set up Masking layer as described above\n",
    "decoder_inputs_masked = Masking(name='decoder_masking')(decoder_inputs)\n",
    "# TODO: Set up Embedding layer as described above\n",
    "decoder_inputs_embedded = Embedding(num_output_words, EMBEDDING_DIM, name='decoder_embedding')(decoder_inputs_masked)\n",
    "\n",
    "# TODO: Create LSTM layer as described above\n",
    "decoder_lstm = LSTM(NUM_LSTM_NODES, return_sequences=True, return_state=True, name='decoder_lstm_1')\n",
    "\n",
    "# TODO: Get output of decoder layer you created above---it must consume the decoder_inputs_embedded and take the final encoder_states saved earlier as its initial_state\n",
    "z, _, _ = decoder_lstm(decoder_inputs_embedded, initial_state=encoder_states1)\n",
    "\n",
    "# TODO: Set up Dense layer as described above\n",
    "decoder_dense = Dense(num_output_words, activation='softmax', name=\"dense_output\")\n",
    "\n",
    "decoder_outputs = decoder_dense(z)\n",
    "\n",
    "# # Define the model that will turn\n",
    "# # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Put it all together into one model, and visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model will use as its inputs a list containing:\n",
    "- the encoder inputs\n",
    "- the decoder inputs\n",
    "\n",
    "And a use as its outputs:\n",
    "- the decoder outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 17)]         0           []                               \n",
      "                                                                                                  \n",
      " encoder_masking (Masking)      (None, 17)           0           ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)     [(None, 23)]         0           []                               \n",
      "                                                                                                  \n",
      " encoder_embedding (Embedding)  (None, 17, 100)      19700       ['encoder_masking[0][0]']        \n",
      "                                                                                                  \n",
      " decoder_masking (Masking)      (None, 23)           0           ['decoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " encoder_lstm_0 (LSTM)          [(None, 17, 256),    365568      ['encoder_embedding[0][0]']      \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " decoder_embedding (Embedding)  (None, 23, 100)      30900       ['decoder_masking[0][0]']        \n",
      "                                                                                                  \n",
      " encoder_lstm_1 (LSTM)          [(None, 256),        525312      ['encoder_lstm_0[0][0]']         \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " decoder_lstm_1 (LSTM)          [(None, 23, 256),    365568      ['decoder_embedding[0][0]',      \n",
      "                                 (None, 256),                     'encoder_lstm_1[0][1]',         \n",
      "                                 (None, 256)]                     'encoder_lstm_1[0][2]']         \n",
      "                                                                                                  \n",
      " dense_output (Dense)           (None, 23, 309)      79413       ['decoder_lstm_1[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,386,461\n",
      "Trainable params: 1,386,461\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TODO: Build the model, passing the arguments as described above...\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"803pt\" height=\"499pt\" viewBox=\"0.00 0.00 889.00 553.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.9 0.9) rotate(0) translate(4 549)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-549 885,-549 885,4 -4,4\"/>\n",
       "<!-- 139685443564304 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>139685443564304</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"116,-498.5 116,-544.5 404,-544.5 404,-498.5 116,-498.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"175\" y=\"-529.3\" font-family=\"Times,serif\" font-size=\"14.00\">encoder_input</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"116,-521.5 234,-521.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"175\" y=\"-506.3\" font-family=\"Times,serif\" font-size=\"14.00\">InputLayer</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"234,-498.5 234,-544.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"268\" y=\"-529.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"234,-521.5 302,-521.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"268\" y=\"-506.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"302,-498.5 302,-544.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"353\" y=\"-529.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 17)]</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"302,-521.5 404,-521.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"353\" y=\"-506.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 17)]</text>\n",
       "</g>\n",
       "<!-- 139685440411872 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>139685440411872</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"110,-415.5 110,-461.5 410,-461.5 410,-415.5 110,-415.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"180\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">encoder_masking</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"110,-438.5 250,-438.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"180\" y=\"-423.3\" font-family=\"Times,serif\" font-size=\"14.00\">Masking</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"250,-415.5 250,-461.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"284\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"250,-438.5 318,-438.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"284\" y=\"-423.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"318,-415.5 318,-461.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"364\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 17)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"318,-438.5 410,-438.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"364\" y=\"-423.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 17)</text>\n",
       "</g>\n",
       "<!-- 139685443564304&#45;&gt;139685440411872 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>139685443564304-&gt;139685440411872</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M260,-498.37C260,-490.15 260,-480.66 260,-471.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"263.5,-471.61 260,-461.61 256.5,-471.61 263.5,-471.61\"/>\n",
       "</g>\n",
       "<!-- 139685399767408 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>139685399767408</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"82,-332.5 82,-378.5 438,-378.5 438,-332.5 82,-332.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">encoder_embedding</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"82,-355.5 242,-355.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">Embedding</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"242,-332.5 242,-378.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"242,-355.5 310,-355.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"310,-332.5 310,-378.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"374\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 17)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"310,-355.5 438,-355.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"374\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 17, 100)</text>\n",
       "</g>\n",
       "<!-- 139685440411872&#45;&gt;139685399767408 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>139685440411872-&gt;139685399767408</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M260,-415.37C260,-407.15 260,-397.66 260,-388.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"263.5,-388.61 260,-378.61 256.5,-388.61 263.5,-388.61\"/>\n",
       "</g>\n",
       "<!-- 139685461176960 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>139685461176960</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"559,-332.5 559,-378.5 847,-378.5 847,-332.5 559,-332.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"618\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">decoder_input</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"559,-355.5 677,-355.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"618\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">InputLayer</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"677,-332.5 677,-378.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"711\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"677,-355.5 745,-355.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"711\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"745,-332.5 745,-378.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"796\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 23)]</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"745,-355.5 847,-355.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"796\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 23)]</text>\n",
       "</g>\n",
       "<!-- 139685461178688 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>139685461178688</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"553,-249.5 553,-295.5 853,-295.5 853,-249.5 553,-249.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"623\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">decoder_masking</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"553,-272.5 693,-272.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"623\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">Masking</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"693,-249.5 693,-295.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"727\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"693,-272.5 761,-272.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"727\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"761,-249.5 761,-295.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"807\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 23)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"761,-272.5 853,-272.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"807\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 23)</text>\n",
       "</g>\n",
       "<!-- 139685461176960&#45;&gt;139685461178688 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>139685461176960-&gt;139685461178688</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M703,-332.37C703,-324.15 703,-314.66 703,-305.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"706.5,-305.61 703,-295.61 699.5,-305.61 706.5,-305.61\"/>\n",
       "</g>\n",
       "<!-- 139685441298928 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>139685441298928</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-249.5 0,-295.5 520,-295.5 520,-249.5 0,-249.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"64\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">encoder_lstm_0</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"0,-272.5 128,-272.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"64\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">LSTM</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"128,-249.5 128,-295.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"128,-272.5 196,-272.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"196,-249.5 196,-295.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"358\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 17, 100)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"196,-272.5 520,-272.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"358\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 17, 256), (None, 256), (None, 256)]</text>\n",
       "</g>\n",
       "<!-- 139685399767408&#45;&gt;139685441298928 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>139685399767408-&gt;139685441298928</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M260,-332.37C260,-324.15 260,-314.66 260,-305.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"263.5,-305.61 260,-295.61 256.5,-305.61 263.5,-305.61\"/>\n",
       "</g>\n",
       "<!-- 139685400489360 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>139685400489360</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"525,-166.5 525,-212.5 881,-212.5 881,-166.5 525,-166.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"605\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">decoder_embedding</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"525,-189.5 685,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"605\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">Embedding</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"685,-166.5 685,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"719\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"685,-189.5 753,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"719\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"753,-166.5 753,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"817\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 23)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"753,-189.5 881,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"817\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 23, 100)</text>\n",
       "</g>\n",
       "<!-- 139685461178688&#45;&gt;139685400489360 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>139685461178688-&gt;139685400489360</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M703,-249.37C703,-241.15 703,-231.66 703,-222.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"706.5,-222.61 703,-212.61 699.5,-222.61 706.5,-222.61\"/>\n",
       "</g>\n",
       "<!-- 139685401768912 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>139685401768912</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"13.5,-166.5 13.5,-212.5 506.5,-212.5 506.5,-166.5 13.5,-166.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"77.5\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">encoder_lstm_1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"13.5,-189.5 141.5,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"77.5\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">LSTM</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"141.5,-166.5 141.5,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"175.5\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"141.5,-189.5 209.5,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"175.5\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"209.5,-166.5 209.5,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"358\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 17, 256)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"209.5,-189.5 506.5,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"358\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 256), (None, 256), (None, 256)]</text>\n",
       "</g>\n",
       "<!-- 139685441298928&#45;&gt;139685401768912 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>139685441298928-&gt;139685401768912</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M260,-249.37C260,-241.15 260,-231.66 260,-222.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"263.5,-222.61 260,-212.61 256.5,-222.61 263.5,-222.61\"/>\n",
       "</g>\n",
       "<!-- 139685400309376 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>139685400309376</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"221,-83.5 221,-129.5 741,-129.5 741,-83.5 221,-83.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"285\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">decoder_lstm_1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"221,-106.5 349,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"285\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">LSTM</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"349,-83.5 349,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"349,-106.5 417,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"417,-83.5 417,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"579\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 23, 100), (None, 256), (None, 256)]</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"417,-106.5 741,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"579\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 23, 256), (None, 256), (None, 256)]</text>\n",
       "</g>\n",
       "<!-- 139685400489360&#45;&gt;139685400309376 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>139685400489360-&gt;139685400309376</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M642.63,-166.47C614.25,-156.12 580.24,-143.71 550.76,-132.95\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"551.95,-129.66 541.36,-129.52 549.55,-136.24 551.95,-129.66\"/>\n",
       "</g>\n",
       "<!-- 139685401768912&#45;&gt;139685400309376 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>139685401768912-&gt;139685400309376</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M320.1,-166.47C348.23,-156.16 381.92,-143.82 411.18,-133.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"412.73,-136.25 420.91,-129.52 410.32,-129.68 412.73,-136.25\"/>\n",
       "</g>\n",
       "<!-- 139685321087728 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>139685321087728</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"326.5,-0.5 326.5,-46.5 635.5,-46.5 635.5,-0.5 326.5,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">dense_output</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"326.5,-23.5 439.5,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"439.5,-0.5 439.5,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"473.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"439.5,-23.5 507.5,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"473.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"507.5,-0.5 507.5,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"571.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 23, 256)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"507.5,-23.5 635.5,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"571.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 23, 309)</text>\n",
       "</g>\n",
       "<!-- 139685400309376&#45;&gt;139685321087728 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>139685400309376-&gt;139685321087728</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M481,-83.37C481,-75.15 481,-65.66 481,-56.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"484.5,-56.61 481,-46.61 477.5,-56.61 484.5,-56.61\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the model and sanity check it...\n",
    "# SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "SVG(model_to_dot(model, show_shapes=True, dpi=65).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_data = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_target_data will be ahead by one timestep\n",
    "# and will not include the start token.\n",
    "decoder_target_data = np.zeros(y_train_one_hot.shape)\n",
    "decoder_target_data[:,:-1] = y_train_one_hot[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_target_data_test = np.zeros(y_test_one_hot.shape)\n",
    "decoder_target_data_test[:,:-1] = y_test_one_hot[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0  69 185  33  91  93 124 107  87  88  65  13  93 177  56  17] [277 287  58 300 122 252  12 289 251 186 178 272 266 289 214 184   0   0\n",
      "   0   0   0   0   0] [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[277 287] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "(3499, 17) (3499, 23) (3499, 23, 309)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data[0], decoder_input_data[0], decoder_target_data[0])\n",
    "print(decoder_input_data[0][:2], decoder_target_data[0][:1])\n",
    "\n",
    "print(encoder_input_data.shape, decoder_input_data.shape, \n",
    "      decoder_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set optimizer to be the Adam optimizer with a learning rate of .001\n",
    "optimizer = Adam() # default learning rate is 0.001\n",
    "\n",
    "# TODO: Compile the model using the optimizer you created above and the categorical cross-entropy loss\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: We've used various callbacks before to do things like early stopping, and model\n",
    "#       checkpointing, and we've mentioned that sometimes you want to dynamically change\n",
    "#       the learning rate over time, taking big steps at first, and smaller ones later,\n",
    "#       when you may be closer to the target.  The callback below reduces the learning\n",
    "#       rate when a metric has stopped improving---when learning seems to be stalling out,\n",
    "#       shrinking the learning rate by a healthy factor can help zero in on the optimum.\n",
    "#\n",
    "#       Consult the Keras docs on `ReduceLROnPlateau` and answer the question below.\n",
    "lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, verbose=1, mode='auto', \n",
    "                                cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION: Understanding `ReduceLROnPlateau`\n",
    "\n",
    "In your own words, describe what `ReduceLROnPlateau` does and why you might want to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANSWER:\n",
    "\n",
    "Reduces learning rate by monitoring a metric like accurary or in our case, the validation loss. If the metric isn't improving after a user specified number of epochs or patience, ReduceLROnPlateau reduces learning rate by a user specified factor which in our case will reduce by half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you've forgotten the details of how the `EarlyStopping` callback works, or if you've forgotten\n",
    "# the general idea, consult the http://keras.io documentation on it to refresh your memory.\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "55/55 [==============================] - 22s 306ms/step - loss: 3.1713 - val_loss: 2.5054 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "55/55 [==============================] - 14s 256ms/step - loss: 2.2958 - val_loss: 2.0595 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "55/55 [==============================] - 14s 248ms/step - loss: 1.8043 - val_loss: 1.5536 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "55/55 [==============================] - 14s 249ms/step - loss: 1.3727 - val_loss: 1.2099 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "55/55 [==============================] - 14s 264ms/step - loss: 1.1036 - val_loss: 1.0164 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "55/55 [==============================] - 13s 244ms/step - loss: 0.9573 - val_loss: 0.8984 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "55/55 [==============================] - 16s 287ms/step - loss: 0.8723 - val_loss: 0.8426 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "55/55 [==============================] - 14s 261ms/step - loss: 0.8176 - val_loss: 0.7928 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "55/55 [==============================] - 14s 248ms/step - loss: 0.7743 - val_loss: 0.7626 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "55/55 [==============================] - 13s 229ms/step - loss: 0.7383 - val_loss: 0.7268 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "55/55 [==============================] - 14s 253ms/step - loss: 0.7091 - val_loss: 0.7004 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "55/55 [==============================] - 12s 224ms/step - loss: 0.6753 - val_loss: 0.6655 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "55/55 [==============================] - 13s 240ms/step - loss: 0.6451 - val_loss: 0.6434 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "55/55 [==============================] - 14s 253ms/step - loss: 0.6182 - val_loss: 0.6180 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "55/55 [==============================] - 16s 287ms/step - loss: 0.5955 - val_loss: 0.6021 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "55/55 [==============================] - 14s 247ms/step - loss: 0.5780 - val_loss: 0.5983 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "55/55 [==============================] - 12s 222ms/step - loss: 0.5723 - val_loss: 0.5635 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "55/55 [==============================] - 15s 279ms/step - loss: 0.5458 - val_loss: 0.5533 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "55/55 [==============================] - 14s 259ms/step - loss: 0.5249 - val_loss: 0.5379 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "55/55 [==============================] - 13s 244ms/step - loss: 0.5093 - val_loss: 0.5230 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "55/55 [==============================] - 14s 251ms/step - loss: 0.4974 - val_loss: 0.5143 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "55/55 [==============================] - 14s 259ms/step - loss: 0.4845 - val_loss: 0.5071 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "55/55 [==============================] - 14s 249ms/step - loss: 0.4738 - val_loss: 0.4950 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "55/55 [==============================] - 13s 236ms/step - loss: 0.4607 - val_loss: 0.4875 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "55/55 [==============================] - 14s 257ms/step - loss: 0.4658 - val_loss: 0.4765 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "55/55 [==============================] - 15s 273ms/step - loss: 0.4481 - val_loss: 0.4690 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "55/55 [==============================] - 14s 247ms/step - loss: 0.4285 - val_loss: 0.4589 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "55/55 [==============================] - 12s 228ms/step - loss: 0.4163 - val_loss: 0.4489 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "55/55 [==============================] - 13s 243ms/step - loss: 0.4051 - val_loss: 0.4349 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "55/55 [==============================] - 15s 267ms/step - loss: 0.3940 - val_loss: 0.4262 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "55/55 [==============================] - 15s 280ms/step - loss: 0.3778 - val_loss: 0.4103 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "55/55 [==============================] - 14s 258ms/step - loss: 0.3636 - val_loss: 0.3979 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "55/55 [==============================] - 13s 241ms/step - loss: 0.3468 - val_loss: 0.3891 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "55/55 [==============================] - 14s 251ms/step - loss: 0.3682 - val_loss: 0.3814 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "55/55 [==============================] - 15s 268ms/step - loss: 0.3271 - val_loss: 0.3735 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "55/55 [==============================] - 15s 265ms/step - loss: 0.3158 - val_loss: 0.3522 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "55/55 [==============================] - 14s 255ms/step - loss: 0.2987 - val_loss: 0.3446 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "55/55 [==============================] - 13s 239ms/step - loss: 0.2885 - val_loss: 0.3340 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "55/55 [==============================] - 14s 248ms/step - loss: 0.2769 - val_loss: 0.3276 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "55/55 [==============================] - 14s 249ms/step - loss: 0.2650 - val_loss: 0.3137 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "55/55 [==============================] - 14s 247ms/step - loss: 0.2561 - val_loss: 0.3123 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "55/55 [==============================] - 13s 239ms/step - loss: 0.2476 - val_loss: 0.3043 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "55/55 [==============================] - 13s 243ms/step - loss: 0.2377 - val_loss: 0.2906 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "55/55 [==============================] - 14s 256ms/step - loss: 0.2259 - val_loss: 0.2818 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "55/55 [==============================] - 14s 256ms/step - loss: 0.2176 - val_loss: 0.2795 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "55/55 [==============================] - 14s 259ms/step - loss: 0.2093 - val_loss: 0.2656 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "55/55 [==============================] - 13s 246ms/step - loss: 0.1968 - val_loss: 0.2568 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "55/55 [==============================] - 13s 245ms/step - loss: 0.1856 - val_loss: 0.2512 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "55/55 [==============================] - 12s 226ms/step - loss: 0.1966 - val_loss: 0.2549 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "55/55 [==============================] - 13s 244ms/step - loss: 0.1806 - val_loss: 0.2374 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "55/55 [==============================] - 15s 266ms/step - loss: 0.1598 - val_loss: 0.2277 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "55/55 [==============================] - 13s 246ms/step - loss: 0.1502 - val_loss: 0.2179 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "55/55 [==============================] - 14s 256ms/step - loss: 0.1402 - val_loss: 0.2160 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "55/55 [==============================] - 15s 266ms/step - loss: 0.1323 - val_loss: 0.2026 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "55/55 [==============================] - 14s 257ms/step - loss: 0.1248 - val_loss: 0.2008 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "55/55 [==============================] - 15s 268ms/step - loss: 0.1170 - val_loss: 0.1909 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "55/55 [==============================] - 16s 294ms/step - loss: 0.1090 - val_loss: 0.1894 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "55/55 [==============================] - 13s 242ms/step - loss: 0.1031 - val_loss: 0.1770 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "55/55 [==============================] - 13s 232ms/step - loss: 0.0965 - val_loss: 0.1793 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "55/55 [==============================] - 15s 269ms/step - loss: 0.0922 - val_loss: 0.1693 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "55/55 [==============================] - 14s 249ms/step - loss: 0.0874 - val_loss: 0.1759 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "55/55 [==============================] - 14s 257ms/step - loss: 0.0816 - val_loss: 0.1630 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "55/55 [==============================] - 14s 262ms/step - loss: 0.0731 - val_loss: 0.1581 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "55/55 [==============================] - 14s 255ms/step - loss: 0.0691 - val_loss: 0.1554 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "55/55 [==============================] - 13s 242ms/step - loss: 0.0684 - val_loss: 0.1547 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "55/55 [==============================] - 15s 270ms/step - loss: 0.0622 - val_loss: 0.1481 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "55/55 [==============================] - 15s 266ms/step - loss: 0.0641 - val_loss: 0.1459 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "55/55 [==============================] - 14s 258ms/step - loss: 0.0531 - val_loss: 0.1432 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "55/55 [==============================] - 13s 237ms/step - loss: 0.0491 - val_loss: 0.1390 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "55/55 [==============================] - 14s 254ms/step - loss: 0.0454 - val_loss: 0.1398 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "55/55 [==============================] - 15s 265ms/step - loss: 0.0433 - val_loss: 0.1376 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "55/55 [==============================] - 15s 265ms/step - loss: 0.0403 - val_loss: 0.1357 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "55/55 [==============================] - 15s 274ms/step - loss: 0.0388 - val_loss: 0.1353 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "55/55 [==============================] - 13s 243ms/step - loss: 0.0376 - val_loss: 0.1344 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "55/55 [==============================] - 13s 236ms/step - loss: 0.0352 - val_loss: 0.1317 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "55/55 [==============================] - 14s 262ms/step - loss: 0.0337 - val_loss: 0.1331 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "55/55 [==============================] - 14s 244ms/step - loss: 0.0300 - val_loss: 0.1311 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "55/55 [==============================] - 14s 250ms/step - loss: 0.0280 - val_loss: 0.1293 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "55/55 [==============================] - 15s 274ms/step - loss: 0.0268 - val_loss: 0.1298 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "55/55 [==============================] - 14s 251ms/step - loss: 0.0253 - val_loss: 0.1295 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "55/55 [==============================] - 14s 256ms/step - loss: 0.0248 - val_loss: 0.1281 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "55/55 [==============================] - 15s 276ms/step - loss: 0.0242 - val_loss: 0.1334 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "55/55 [==============================] - 14s 248ms/step - loss: 0.0243 - val_loss: 0.1263 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "55/55 [==============================] - 14s 254ms/step - loss: 0.0249 - val_loss: 0.1429 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "55/55 [==============================] - 14s 245ms/step - loss: 0.0285 - val_loss: 0.1309 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "55/55 [==============================] - 14s 251ms/step - loss: 0.0451 - val_loss: 0.1374 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.0350\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "55/55 [==============================] - 14s 263ms/step - loss: 0.0350 - val_loss: 0.1496 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "55/55 [==============================] - 14s 257ms/step - loss: 0.0208 - val_loss: 0.1208 - lr: 5.0000e-04\n",
      "Epoch 89/100\n",
      "55/55 [==============================] - 13s 237ms/step - loss: 0.0149 - val_loss: 0.1198 - lr: 5.0000e-04\n",
      "Epoch 90/100\n",
      "55/55 [==============================] - 14s 258ms/step - loss: 0.0137 - val_loss: 0.1195 - lr: 5.0000e-04\n",
      "Epoch 91/100\n",
      "55/55 [==============================] - 14s 247ms/step - loss: 0.0131 - val_loss: 0.1201 - lr: 5.0000e-04\n",
      "Epoch 92/100\n",
      "55/55 [==============================] - 15s 271ms/step - loss: 0.0126 - val_loss: 0.1213 - lr: 5.0000e-04\n",
      "Epoch 93/100\n",
      "55/55 [==============================] - 14s 258ms/step - loss: 0.0121 - val_loss: 0.1207 - lr: 5.0000e-04\n",
      "Epoch 94/100\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.0118\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "55/55 [==============================] - 14s 251ms/step - loss: 0.0118 - val_loss: 0.1213 - lr: 5.0000e-04\n",
      "Epoch 95/100\n",
      "55/55 [==============================] - 14s 249ms/step - loss: 0.0111 - val_loss: 0.1209 - lr: 2.5000e-04\n",
      "Epoch 96/100\n",
      "55/55 [==============================] - 13s 242ms/step - loss: 0.0109 - val_loss: 0.1210 - lr: 2.5000e-04\n",
      "Epoch 97/100\n",
      "55/55 [==============================] - 14s 252ms/step - loss: 0.0108 - val_loss: 0.1214 - lr: 2.5000e-04\n",
      "Epoch 98/100\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "55/55 [==============================] - 15s 263ms/step - loss: 0.0106 - val_loss: 0.1210 - lr: 2.5000e-04\n",
      "Epoch 99/100\n",
      "55/55 [==============================] - 14s 262ms/step - loss: 0.0104 - val_loss: 0.1214 - lr: 1.2500e-04\n",
      "Epoch 100/100\n",
      "55/55 [==============================] - 15s 272ms/step - loss: 0.0103 - val_loss: 0.1213 - lr: 1.2500e-04\n",
      "Epoch 100: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0b0ab574f0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run training\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=NUM_EPOCHS,\n",
    "          validation_data=([X_test, y_test], decoder_target_data_test),\n",
    "          callbacks=[lr_callback, early_stopping_callback])\n",
    "\n",
    "# You might want to watch the training output for the moments where the\n",
    "# learning rate drops due to the effects of the ReduceLROnPlateau callback,\n",
    "# to appreciate what the callback is trying to do for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('s2s.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We have trained a model, but how do we use it to actually translate sentences? We have to do more work ourselves here than with a non-recurrent neural net, so we'll write a function to help out. Here are the steps:\n",
    "\n",
    "1. **Encode**:\n",
    "    1. Run the entire input sentence through the encoder part of the model.\n",
    "    1. Write down the \"context vector\" -- this is the state of the last LSTM encoder layer.<br><br>\n",
    "\n",
    "2. **Decode in a loop**:\n",
    "    1. Seed the decoder LSTM with the context vector.\n",
    "    1. Run a *single step* of the decoder with the input \"`<S>`\" (the start symbol).\n",
    "    1. Store the output. This is a word of the translation!\n",
    "    1. Return to step 2B, but feed in the word from step 2C as the new input. Repeat until the decoder returns \"`</S>`\" (the end symbol)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention!\n",
    "At this point you should work through the following cells, and make sure you understand the\n",
    "set up we're doing.  It will make following the logic of the translate function a lot easier\n",
    "at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 17)]              0         \n",
      "                                                                 \n",
      " encoder_masking (Masking)   (None, 17)                0         \n",
      "                                                                 \n",
      " encoder_embedding (Embeddin  (None, 17, 100)          19700     \n",
      " g)                                                              \n",
      "                                                                 \n",
      " encoder_lstm_0 (LSTM)       [(None, 17, 256),         365568    \n",
      "                              (None, 256),                       \n",
      "                              (None, 256)]                       \n",
      "                                                                 \n",
      " encoder_lstm_1 (LSTM)       [(None, 256),             525312    \n",
      "                              (None, 256),                       \n",
      "                              (None, 256)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 910,580\n",
      "Trainable params: 910,580\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states1)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"477pt\" height=\"349pt\" viewBox=\"0.00 0.00 528.00 387.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.9 0.9) rotate(0) translate(4 383)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-383 524,-383 524,4 -4,4\"/>\n",
       "<!-- 139685443564304 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>139685443564304</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"116,-332.5 116,-378.5 404,-378.5 404,-332.5 116,-332.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"175\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">encoder_input</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"116,-355.5 234,-355.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"175\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">InputLayer</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"234,-332.5 234,-378.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"268\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"234,-355.5 302,-355.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"268\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"302,-332.5 302,-378.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"353\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 17)]</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"302,-355.5 404,-355.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"353\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 17)]</text>\n",
       "</g>\n",
       "<!-- 139685440411872 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>139685440411872</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"110,-249.5 110,-295.5 410,-295.5 410,-249.5 110,-249.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"180\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">encoder_masking</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"110,-272.5 250,-272.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"180\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">Masking</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"250,-249.5 250,-295.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"284\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"250,-272.5 318,-272.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"284\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"318,-249.5 318,-295.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"364\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 17)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"318,-272.5 410,-272.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"364\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 17)</text>\n",
       "</g>\n",
       "<!-- 139685443564304&#45;&gt;139685440411872 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>139685443564304-&gt;139685440411872</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M260,-332.37C260,-324.15 260,-314.66 260,-305.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"263.5,-305.61 260,-295.61 256.5,-305.61 263.5,-305.61\"/>\n",
       "</g>\n",
       "<!-- 139685399767408 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>139685399767408</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"82,-166.5 82,-212.5 438,-212.5 438,-166.5 82,-166.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">encoder_embedding</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"82,-189.5 242,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">Embedding</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"242,-166.5 242,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"242,-189.5 310,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"310,-166.5 310,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"374\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 17)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"310,-189.5 438,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"374\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 17, 100)</text>\n",
       "</g>\n",
       "<!-- 139685440411872&#45;&gt;139685399767408 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>139685440411872-&gt;139685399767408</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M260,-249.37C260,-241.15 260,-231.66 260,-222.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"263.5,-222.61 260,-212.61 256.5,-222.61 263.5,-222.61\"/>\n",
       "</g>\n",
       "<!-- 139685441298928 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>139685441298928</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-83.5 0,-129.5 520,-129.5 520,-83.5 0,-83.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"64\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">encoder_lstm_0</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"0,-106.5 128,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"64\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">LSTM</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"128,-83.5 128,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"128,-106.5 196,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"196,-83.5 196,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"358\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 17, 100)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"196,-106.5 520,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"358\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 17, 256), (None, 256), (None, 256)]</text>\n",
       "</g>\n",
       "<!-- 139685399767408&#45;&gt;139685441298928 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>139685399767408-&gt;139685441298928</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M260,-166.37C260,-158.15 260,-148.66 260,-139.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"263.5,-139.61 260,-129.61 256.5,-139.61 263.5,-139.61\"/>\n",
       "</g>\n",
       "<!-- 139685401768912 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>139685401768912</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"13.5,-0.5 13.5,-46.5 506.5,-46.5 506.5,-0.5 13.5,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"77.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">encoder_lstm_1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"13.5,-23.5 141.5,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"77.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">LSTM</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"141.5,-0.5 141.5,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"175.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"141.5,-23.5 209.5,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"175.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"209.5,-0.5 209.5,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"358\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 17, 256)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"209.5,-23.5 506.5,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"358\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 256), (None, 256), (None, 256)]</text>\n",
       "</g>\n",
       "<!-- 139685441298928&#45;&gt;139685401768912 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>139685441298928-&gt;139685401768912</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M260,-83.37C260,-75.15 260,-65.66 260,-56.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"263.5,-56.61 260,-46.61 256.5,-56.61 263.5,-56.61\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(encoder_model, show_shapes=True, dpi=65).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " decoder_input (InputLayer)     [(None, 23)]         0           []                               \n",
      "                                                                                                  \n",
      " decoder_masking (Masking)      (None, 23)           0           ['decoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " decoder_embedding (Embedding)  (None, 23, 100)      30900       ['decoder_masking[0][0]']        \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " decoder_lstm_1 (LSTM)          [(None, 23, 256),    365568      ['decoder_embedding[0][0]',      \n",
      "                                 (None, 256),                     'input_1[0][0]',                \n",
      "                                 (None, 256)]                     'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_output (Dense)           (None, 23, 309)      79413       ['decoder_lstm_1[1][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 475,881\n",
      "Trainable params: 475,881\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Make sure you see how states are interacting between encoder\n",
    "#       and decoder here...  the model visualizations and talking\n",
    "#       through what they do may be illuminating.\n",
    "\n",
    "decoder_state_input_h = Input(shape=(NUM_LSTM_NODES,))\n",
    "decoder_state_input_c = Input(shape=(NUM_LSTM_NODES,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs1, state_h1, state_c1 = decoder_lstm(decoder_inputs_embedded, initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_states1 = [state_h1, state_c1]\n",
    "decoder_outputs = decoder_dense(decoder_outputs1)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs,\n",
    "                      [decoder_outputs] + decoder_states1)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"856pt\" height=\"349pt\" viewBox=\"0.00 0.00 948.00 387.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.9 0.9) rotate(0) translate(4 383)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-383 944,-383 944,4 -4,4\"/>\n",
       "<!-- 139685461176960 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>139685461176960</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"34,-332.5 34,-378.5 322,-378.5 322,-332.5 34,-332.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"93\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">decoder_input</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"34,-355.5 152,-355.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"93\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">InputLayer</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"152,-332.5 152,-378.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"186\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"152,-355.5 220,-355.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"186\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"220,-332.5 220,-378.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 23)]</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"220,-355.5 322,-355.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 23)]</text>\n",
       "</g>\n",
       "<!-- 139685461178688 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>139685461178688</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"28,-249.5 28,-295.5 328,-295.5 328,-249.5 28,-249.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"98\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">decoder_masking</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"28,-272.5 168,-272.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"98\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">Masking</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"168,-249.5 168,-295.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"202\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"168,-272.5 236,-272.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"202\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"236,-249.5 236,-295.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"282\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 23)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"236,-272.5 328,-272.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"282\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 23)</text>\n",
       "</g>\n",
       "<!-- 139685461176960&#45;&gt;139685461178688 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>139685461176960-&gt;139685461178688</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M178,-332.37C178,-324.15 178,-314.66 178,-305.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"181.5,-305.61 178,-295.61 174.5,-305.61 181.5,-305.61\"/>\n",
       "</g>\n",
       "<!-- 139685400489360 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>139685400489360</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-166.5 0,-212.5 356,-212.5 356,-166.5 0,-166.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"80\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">decoder_embedding</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"0,-189.5 160,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"80\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">Embedding</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"160,-166.5 160,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"194\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"160,-189.5 228,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"194\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"228,-166.5 228,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"292\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 23)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"228,-189.5 356,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"292\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 23, 100)</text>\n",
       "</g>\n",
       "<!-- 139685461178688&#45;&gt;139685400489360 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>139685461178688-&gt;139685400489360</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M178,-249.37C178,-241.15 178,-231.66 178,-222.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"181.5,-222.61 178,-212.61 174.5,-222.61 181.5,-222.61\"/>\n",
       "</g>\n",
       "<!-- 139685400309376 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>139685400309376</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"251,-83.5 251,-129.5 771,-129.5 771,-83.5 251,-83.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"315\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">decoder_lstm_1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"251,-106.5 379,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"315\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">LSTM</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"379,-83.5 379,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"413\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"379,-106.5 447,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"413\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"447,-83.5 447,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"609\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 23, 100), (None, 256), (None, 256)]</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"447,-106.5 771,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"609\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 23, 256), (None, 256), (None, 256)]</text>\n",
       "</g>\n",
       "<!-- 139685400489360&#45;&gt;139685400309376 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>139685400489360-&gt;139685400309376</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M268.55,-166.47C312.51,-155.78 365.46,-142.9 410.65,-131.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"411.57,-135.29 420.46,-129.52 409.92,-128.48 411.57,-135.29\"/>\n",
       "</g>\n",
       "<!-- 139685306002160 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>139685306002160</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"374,-166.5 374,-212.5 648,-212.5 648,-166.5 374,-166.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"421.5\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">input_1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"374,-189.5 469,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"421.5\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">InputLayer</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"469,-166.5 469,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"503\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"469,-189.5 537,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"503\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"537,-166.5 537,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"592.5\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 256)]</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"537,-189.5 648,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"592.5\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 256)]</text>\n",
       "</g>\n",
       "<!-- 139685306002160&#45;&gt;139685400309376 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>139685306002160-&gt;139685400309376</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M511,-166.37C511,-158.15 511,-148.66 511,-139.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"514.5,-139.61 511,-129.61 507.5,-139.61 514.5,-139.61\"/>\n",
       "</g>\n",
       "<!-- 139685306001056 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>139685306001056</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"666,-166.5 666,-212.5 940,-212.5 940,-166.5 666,-166.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"713.5\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">input_2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"666,-189.5 761,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"713.5\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">InputLayer</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"761,-166.5 761,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"795\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"761,-189.5 829,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"795\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"829,-166.5 829,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"884.5\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 256)]</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"829,-189.5 940,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"884.5\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 256)]</text>\n",
       "</g>\n",
       "<!-- 139685306001056&#45;&gt;139685400309376 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>139685306001056-&gt;139685400309376</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M723.6,-166.47C685.45,-155.89 639.59,-143.17 600.24,-132.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"600.96,-128.82 590.39,-129.52 599.09,-135.57 600.96,-128.82\"/>\n",
       "</g>\n",
       "<!-- 139685321087728 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>139685321087728</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"356.5,-0.5 356.5,-46.5 665.5,-46.5 665.5,-0.5 356.5,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"413\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">dense_output</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"356.5,-23.5 469.5,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"413\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"469.5,-0.5 469.5,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"503.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"469.5,-23.5 537.5,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"503.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"537.5,-0.5 537.5,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"601.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 23, 256)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"537.5,-23.5 665.5,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"601.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 23, 309)</text>\n",
       "</g>\n",
       "<!-- 139685400309376&#45;&gt;139685321087728 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>139685400309376-&gt;139685321087728</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M511,-83.37C511,-75.15 511,-65.66 511,-56.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"514.5,-56.61 511,-46.61 507.5,-56.61 514.5,-56.61\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(decoder_model, show_shapes=True, dpi=65).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translating Sequences\n",
    "\n",
    "The `translate_sequence` method works as described above, but its internals may seem a bit\n",
    "gnarly and complicated because it has to deal with:\n",
    "- getting the hidden and internal states of the encoder model\n",
    "- generating a container for the target/output sequence and pre-populating it with the start symbol\n",
    "- looping to call the decoder to make a prediction given the target sequence so far + the encoder's passed on states\n",
    "- picking apart the output, which you recall is a softmax the width of the vocabulary with each entry being the probability that the corresponding word comes next\n",
    "- convert word indices back to words and accumulating them into the translation so far\n",
    "- and figuring out when to stop.\n",
    "\n",
    "Because it's so easy to get little things wrong in such a loop, it's provided without requiring you to add anything.\n",
    "You'll probably benefit most from it, if you get it started running, and then start picking apart the code line by\n",
    "line, making sure you understand:\n",
    "- how it relates to the encoder and decoder networks you built up above\n",
    "- the details of how it's converted predicted probabilities into word vectors and in turn into words\n",
    "- the general looping structure used to make the decoder feed itself its own output repeatedly and build a growing translated output\n",
    "\n",
    "Understanding a thing like this function is one place where notebooks are kind of crappy.  It can be a lot\n",
    "more illuminating to single step through the function in a debugger and see what it's doing at each step,\n",
    "and how states are mutating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    h1, c1 = encoder_model.predict(input_seq)\n",
    "    states_value1 = [h1, c1]\n",
    "    # Generate empty target sequence of length 1 (one-hot encoded).\n",
    "    #target_seq = np.zeros((1, num_output_words))\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first word of target sequence with the start symbol.\n",
    "    #target_seq[0, word_to_index2['<S>']] = 1.\n",
    "    target_seq[0,0] = word_to_index2['<S>']\n",
    "    \n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    step = 0\n",
    "    while not stop_condition:\n",
    "        #print('step:', step)\n",
    "        #print(states_value1[0][0][0:5])\n",
    "    \n",
    "        output_tokens, h1, c1  = decoder_model.predict(\n",
    "            [target_seq] + states_value1)\n",
    "\n",
    "        # Sample a token\n",
    "        #print(output_tokens)\n",
    "        #sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, 0, :])\n",
    "        sampled_word = index_to_word2[sampled_token_index]\n",
    "        #print(sampled_word)\n",
    "        decoded_sentence += sampled_word + ' '\n",
    "        step += 1\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_word == '</S>' or step > max_output_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        #target_seq = np.zeros((1, num_output_words))\n",
    "        #target_seq[0, sampled_token_index] = 1.\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        # Update states\n",
    "        states_value1 = [h1, c1]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'most', 'loved', 'fruit', 'is', 'the', 'banana', ',', 'but', 'their', 'most', 'loved', 'is', 'the', 'orange', '.', '<MASK>']\n",
      "1/1 [==============================] - 1s 664ms/step\n",
      "1/1 [==============================] - 1s 541ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "mon fruit le plus aimé est la banane , mais leur plus aimé est l'orange . <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> \n",
      "['she', 'likes', 'apples', ',', 'oranges', ',', 'and', 'strawberries', '.', '<MASK>', '<MASK>', '<MASK>', '<MASK>', '<MASK>', '<MASK>', '<MASK>', '<MASK>']\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "elle aime les pommes , les oranges et les fraises . <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> \n",
      "['the', 'banana', 'is', 'our', 'least', 'favorite', 'fruit', ',', 'but', 'the', 'grape', 'is', 'their', 'least', 'favorite', '.', '<MASK>']\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "la banane est notre fruit préféré moins , mais le raisin est leur moins préféré . <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> \n",
      "['paris', 'is', 'usually', 'chilly', 'during', 'december', ',', 'and', 'it', 'is', 'never', 'cold', 'in', 'april', '.', '<MASK>', '<MASK>']\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "paris est généralement froid en décembre , et il est jamais froid en avril . <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> \n",
      "['he', 'likes', 'mangoes', ',', 'oranges', ',', 'and', 'lemons', '.', '<MASK>', '<MASK>', '<MASK>', '<MASK>', '<MASK>', '<MASK>', '<MASK>', '<MASK>']\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "il aime les mangues , les oranges , les citrons et les . <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> \n",
      "['india', 'is', 'sometimes', 'rainy', 'during', 'january', ',', 'and', 'it', 'is', 'pleasant', 'in', 'february', '.', '<MASK>', '<MASK>', '<MASK>']\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "l' inde est parfois pluvieux en janvier , et il est agréable en février . <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> \n",
      "['china', 'is', 'usually', 'relaxing', 'during', 'june', ',', 'but', 'it', 'is', 'never', 'quiet', 'in', 'summer', '.', '<MASK>', '<MASK>']\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "chine est relaxant habituellement en juin , mais il est jamais tranquille en été . <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> \n",
      "['paris', 'is', 'freezing', 'during', 'fall', ',', 'and', 'it', 'is', 'never', 'dry', 'in', 'spring', '.', '<MASK>', '<MASK>', '<MASK>']\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "paris est le gel pendant l' automne , et il est jamais sec au printemps . <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> \n",
      "['new', 'jersey', 'is', 'sometimes', 'snowy', 'during', 'july', ',', 'but', 'it', 'is', 'sometimes', 'hot', 'in', 'december', '.', '<MASK>']\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "new jersey est parfois enneigée en juillet , mais il est parfois chaud en décembre . <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> \n",
      "['china', 'is', 'sometimes', 'chilly', 'during', 'august', ',', 'but', 'it', 'is', 'usually', 'wonderful', 'in', 'january', '.', '<MASK>', '<MASK>']\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "la chine est parfois froid au mois d' août , mais il est généralement merveilleux en janvier . <MASK> <MASK> <MASK> <MASK> <MASK> <MASK> \n"
     ]
    }
   ],
   "source": [
    "# Look at some translations...  Note we may well produce translations that are not the\n",
    "# very same ones seen in the test set!\n",
    "for i in range(10):\n",
    "    print(indices_to_sentence(X_test[i], index_to_word1)[::-1])\n",
    "    print(translate_sequence(np.expand_dims(X_test[i], axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION: How Good Are These Results?\n",
    "\n",
    "1. Do you speak or read French at all?  If so, how well?\n",
    "2. How do these translations look to you, if you know enough French to evaluate them?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANSWER:\n",
    "\n",
    "I don't speak or read French. I used Google to translate the French result. \n",
    "As per Google for the input: la chine est parfois froid au mois d' août , mais il est généralement merveilleux en janvier,\n",
    "this is the output: China is sometimes cold in August, but it is usually wonderful in January.\n",
    "So the model isn't doing well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1516242594570646706\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
